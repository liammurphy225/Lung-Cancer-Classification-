---
title: "Lung Cancer"
author: "Liam Murphy"
date: "2024-11-14"
output: html_document
---

```{r setup, include=FALSE}

library(readr)
library(readxl)
library(caret)
library(randomForest)
library(pROC)
library(ggplot2)
library(reshape2)
library(tidyverse)
```

```{r Load Data, include=FALSE}

getwd()
setwd("C:/Users/liamm/OneDrive - University of Massachusetts/Documents/R Projects")
lc_data <- read.csv("survey lung cancer.csv")

```

```{r}
# View the structure of the dataset
str(lc_data)

# Summary of the dataset
summary(lc_data)

# Check for NAs
colSums(is.na(lc_data))
```



```{r}
# Convert character columns/integer to factors for classification 

lc_data <- data.frame(lapply(lc_data, function(x) {
  if (is.integer(x) || is.character(x)) {
    as.factor(x)  # Convert integer and character columns to factors
  } else {
    x  # Keep other column types unchanged
  }
}))

# If Age is a factor and needs to be numeric, convert it by first ensuring the levels are numeric
lc_data$AGE <- as.numeric(as.character(lc_data$AGE))  # Convert factor to numeric properly

# Recode 1 to "No" and 2 to "Yes" for all relevant columns
lc_data <- lc_data %>%
  mutate(across(where(~ all(. %in% c(1, 2))), 
                ~ recode(.x, `1` = "No", `2` = "Yes")))

# Check structure after change
str(lc_data)

```

```{r}
set.seed(123)
trainIndex <- createDataPartition(lc_data$LUNG_CANCER, p = 0.7, list = FALSE)  # specify the response variable
trainData <- lc_data[trainIndex, ]
testData <- lc_data[-trainIndex, ]


```


```{r}
# Ensure that AGE is numeric
lc_data$AGE <- as.numeric(lc_data$AGE)

# Filter the dataset for males who are positive for lung cancer
males_lung_cancer <- subset(lc_data, GENDER == "M" & LUNG_CANCER == "YES")

# Plot the age distribution for these individuals
ggplot(males_lung_cancer, aes(x = AGE)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7, stat = "count") +
  labs(title = "Age Distribution for Males Positive for Lung Cancer",
       x = "Age",
       y = "Frequency") +
  theme_minimal()

# Filter the dataset for females who are positive for lung cancer
females_lung_cancer <- subset(lc_data, GENDER == "F" & LUNG_CANCER == "YES")

# Plot the age distribution for these individuals
ggplot(females_lung_cancer, aes(x = AGE)) +
  geom_histogram(binwidth = 1, fill = "pink", color = "black", alpha = 0.7, stat = "count") +
  labs(title = "Age Distribution for Females Positive for Lung Cancer",
       x = "Age",
       y = "Frequency") +
  theme_minimal()




```


Explore bivariate relationships with lung cancer. 

```{r}

# Create a loop to generate proportion plots for all variables vs lung cancer
for (var in colnames(lc_data)) {
  # Skip the LUNG_CANCER column as it's used for grouping
  if (var != "LUNG_CANCER") {
    p <- ggplot(lc_data, aes_string(x = var, fill = "LUNG_CANCER")) +
      geom_bar(position = "fill") +
      labs(title = paste("Proportion of LUNG CANCER by", var), x = var, y = "Proportion") +
      theme_minimal()
    
    # Print the plot
    print(p)
  }
}


```







```{r}

# Train Logistic Regression Model

logit_model <- train(
  LUNG_CANCER ~ ., data = trainData,
  method = "glm",  # 'glm' method for Generalized Linear Model (logistic regression)
  family = binomial(),  # Ensure logistic regression
  trControl = trainControl(method = "cv", number = 5)
)

# Print Logistic Regression Model Summary
print(logit_model)
```
```{r}
# Make predictions
predictions_logistic <- predict(logit_model, testData)

# Confusion Matrix
confusionMatrix(predictions_logistic, testData$LUNG_CANCER)

```


ROC Curve:

True Positive Rate (TPR) or Sensitivity:

TPR
=
True Positives/True Positives + False Positive 


Measures the proportion of actual positives correctly identified.

False Positive Rate (FPR):

FPR
=
False Positives /False Positives + True Negatives


Measures the proportion of actual negatives incorrectly identified as positive.

Thresholds:

The model assigns probabilities to each instance, and the ROC curve is generated by varying the decision threshold for classifying an observation as "positive" or "negative."



```{r}


# Get predicted probabilities
probabilities <- predict(logit_model, testData, type = "prob")[,2]

# Compute ROC curve
roc_curve <- roc(testData$LUNG_CANCER, probabilities)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve for Logistic Regression")
auc <- auc(roc_curve)
cat("AUC:", auc, "\n")

```
The X-axis represents FDR or how many negative samples were incorrectly classified. 

The y-axis represents TPR or how many positive samples were correctly classified.

Top left corner is the ideal performance, where TPR=1 and FPR=0

A model whose ROC curve is close to the diagonal line has little discriminatory power. 

```{r}


# Create confusion matrix
conf_matrix <- confusionMatrix(predictions_logistic, testData$LUNG_CANCER)

# Convert to table
conf_mat_table <- as.table(conf_matrix$table)

# Plot heatmap
ggplot(as.data.frame(conf_mat_table), aes(Reference, Prediction, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), color = "black") +
  labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
  theme_minimal()


```

```{r}
var_imp <- varImp(logit_model, scale = FALSE)

# Plot variable importance
plot(var_imp, main = "Variable Importance for Logistic Regression")


```


```{r}

# Define the custom grid with only the 'mtry' parameter
# Generates a sequence of numbers starting at 2  going up to the "# of columns" in the data set increment by 1

tune_grid <- expand.grid(mtry = seq(2, ncol(trainData) - 1, by = 1))

set.seed(123)

# Train the Random Forest model
rf_model <- train(
  LUNG_CANCER ~ ., data = trainData,
  method = "rf",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = tune_grid
)

# Model summary
print(rf_model)


```



```{r}
# Make predictions
predictions_rf <- predict(rf_model, testData)

# Confusion Matrix
confusionMatrix(predictions_rf, testData$LUNG_CANCER)

```

The Out-of-Bag (OOB) error is a performance metric used with Random Forest models. It provides an estimate of the model's prediction error without needing a separate test data set. When building the decision tree the training data is sampled with replacement which creates a "bootstrapped sample". The sample that is not included in the bootstrapped sample is considered the "out-of-bag" sample. The OOB error is the proportion of misclassified observations in the OOB data, averaged across all trees in the Random Forest. OOB error approximates how well the model will perform on unseen data.

```{r}

# Extract and print OOB error
oob_error <- rf_model$err.rate[500, "OOB"]
cat("OOB Error Rate:", oob_error, "\n")

# Visualize OOB error over trees
plot(rf_model, main = "OOB Error vs. Number of Trees")

```


```{r}


# Get predicted probabilities
probabilities_rf <- predict(rf_model, testData, type = "prob")[,2]

# Compute ROC curve
roc_rf <- roc(testData$LUNG_CANCER, probabilities_rf)

# Plot the ROC curve
plot(roc_rf, main = "ROC Curve for Random Forest Model", col = "blue", lwd = 2)
auc_rf <- auc(roc_rf)
cat("AUC:", auc_rf, "\n")

```

```{r}


# Generate confusion matrix
conf_matrix_rf <- confusionMatrix(predictions_rf, testData$LUNG_CANCER)

# Convert to a table
conf_mat_table_rf <- as.table(conf_matrix_rf$table)

# Plot heatmap
ggplot(as.data.frame(conf_mat_table_rf), aes(Reference, Prediction, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = Freq), color = "black") +
  labs(title = "Confusion Matrix Heatmap (RF)", x = "Actual", y = "Predicted") +
  theme_minimal()
```








```{r}


# Extract variable importance
var_imp_rf <- varImp(rf_model, scale = TRUE)

# Convert to data frame for ggplot
var_imp_df <- var_imp_rf$importance
var_imp_df$Variable <- rownames(var_imp_df)
var_imp_df <- var_imp_df[order(var_imp_df$Overall, decreasing = TRUE), ]

# Limit to top N variables (e.g., top 10)
top_n <- 10
var_imp_df_top <- head(var_imp_df, top_n)

# Plot with ggplot2
ggplot(var_imp_df_top, aes(x = reorder(Variable, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Top 10 Variable Importance for Random Forest",
       x = "Predictor",
       y = "Importance") +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1))  # Make text horizontal for readability


```



```{r}


# Train a KNN model
set.seed(123)  # Set seed for reproducibility
knn_model <- train(
  LUNG_CANCER ~ ., data = trainData,
  method = "knn",  # Specify KNN method
  trControl = trainControl(method = "cv", number = 5),  # 5-fold cross-validation
  tuneGrid = expand.grid(k = 3:10)  # Tune the number of neighbors (k)
)

# Model summary
print(knn_model)
```

```{r}
# Make predictions on the test data
predictions_knn <- predict(knn_model, testData)

# Confusion Matrix
confusionMatrix(predictions_knn, testData$LUNG_CANCER)
```

```{r}
# Plot KNN performance for different k values
plot(knn_model)
```
According to the accuracy plot  k = 3 and k = 5 have the best accuracy. Therefore, k = 5 was used for the model. 

```{r}
# Get predicted probabilities
pred_probs_knn <- predict(knn_model, testData, type = "prob")

# Plot ROC curve
roc_curve <- roc(testData$LUNG_CANCER, pred_probs_knn[, 2])  # Assuming the second column is the positive class
plot(roc_curve, main = "ROC Curve for KNN")
```

The results from the ROC curve suggest a strong model performance. Normally models closer to .5 are considered to have no discriminatory ability and models closer to 1 are considered to have high discriminatory ability. 

```{r}

# Generate predictions from KNN model (assuming knn_model and testData are defined)
predictions_knn <- predict(knn_model, testData)

# Generate confusion matrix
cm <- confusionMatrix(predictions_knn, testData$LUNG_CANCER)

# Convert confusion matrix into a data frame for plotting
cm_data <- as.data.frame(cm$table)
colnames(cm_data) <- c("Predicted", "Actual", "Freq")

# Create a heatmap of the confusion matrix
ggplot(cm_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() + 
  geom_text(aes(label = Freq), color = "black", size = 5) +
  scale_fill_gradient(low = "red", high = "blue") +
  labs(title = "Confusion Matrix Heatmap for KNN", x = "Actual", y = "Predicted") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```




```{r}
# Train a Linear Discriminant Analysis (LDA) model
lda_model <- train(
  LUNG_CANCER ~ ., data = trainData,
  method = "lda",
  trControl = trainControl(method = "cv", number = 5)
)

# Print the LDA model summary
print(lda_model)

# Make predictions using the LDA model
predictions_lda <- predict(lda_model, testData)

# Confusion Matrix for LDA
cm_lda <- confusionMatrix(predictions_lda, testData$LUNG_CANCER)
print(cm_lda)

# Plot confusion matrix heatmap for LDA
cm_data_lda <- as.data.frame(cm_lda$table)
colnames(cm_data_lda) <- c("Predicted", "Actual", "Freq")
ggplot(cm_data_lda, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() + 
  geom_text(aes(label = Freq), color = "white", size = 5) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Confusion Matrix Heatmap for LDA", x = "Actual", y = "Predicted") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```